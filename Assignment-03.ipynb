{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a067b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Before your go ----\n",
    "# 1. Rename Assignment-03-###.ipynb where ### is your student ID.\n",
    "# 2. The deadline of Assignment-03 is 23:59pm, 05-31-2023\n",
    "\n",
    "\n",
    "# --- Explore HMM POS Taggers using Brown corpus ---\n",
    "# In this assignment, you will explore two taggers for a Brown corpus.\n",
    "# import your packages here\n",
    "\n",
    "from nltk import FreqDist, MLEProbDist, LidstoneProbDist, ConditionalFreqDist, ConditionalProbDist\n",
    "from nltk.util import unique_list\n",
    "from nltk.tag import HiddenMarkovModelTagger\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bb55db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 --- Load and explore your data ---\n",
    "# 1). load train/test samples from Brown corpus files, brown-train.txt, brown-test.txt.\n",
    "# 2). load all 12 tags from brown-tag.txt and print it out\n",
    "# 3). counting how many sentences and words in both train and test datasets.\n",
    "# 4). for each tag, counting how many words in train and test. e.g, tag1: [count_tr, count_te]\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2936db66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown-train.txt\n",
      "('mr.', 'NOUN')('podger', 'NOUN')('had', 'VERB')('thanked', 'VERB')('him', 'PRON')...\n",
      "('but', 'CONJ')('there', 'PRT')('seemed', 'VERB')('to', 'PRT')('be', 'VERB')...\n",
      "('such', 'PRT')('an', 'DET')('instrument', 'NOUN')('is', 'VERB')('expected', 'VERB')...\n",
      "('my', 'DET')('future', 'ADJ')('plans', 'NOUN')('are', 'VERB')('to', 'PRT')...\n",
      "('we', 'PRON')('ran', 'VERB')('east', 'NOUN')('for', 'ADP')('about', 'ADV')...\n",
      "...\n",
      "\n",
      "brown-test.txt\n",
      "('``', '.')(\"i've\", 'PRT')('got', 'VERB')('cancer', 'NOUN')(',', '.')...\n",
      "('the', 'DET')('need', 'NOUN')('to', 'PRT')('protect', 'VERB')('the', 'DET')...\n",
      "('one', 'NUM')('of', 'ADP')('his', 'DET')('innovations', 'NOUN')('was', 'VERB')...\n",
      "('she', 'PRON')('rubbed', 'VERB')('her', 'PRON')('eyes', 'NOUN')('and', 'CONJ')...\n",
      "('``', '.')('get', 'VERB')('into', 'ADP')('your', 'DET')('hovel', 'NOUN')...\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(path, print_data=True):\n",
    "    with open(path) as f:\n",
    "        tmp=[item.strip().split(\"\\t\") for item in f.readlines()]\n",
    "    dataset=[]\n",
    "    for item in tmp:\n",
    "        if(len(item)==1 and item[0]!=\"\"):\n",
    "            dataset.append([])\n",
    "        elif(len(item)==2):\n",
    "            dataset[-1].append(tuple((item[0].lower(),item[1]))) # 让word小写\n",
    "    if(print_data):\n",
    "        print(path)\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                print(dataset[i][j],end=\"\")\n",
    "            print(\"...\")\n",
    "        print(\"...\\n\")\n",
    "    return dataset\n",
    "\n",
    "trainset=load_dataset(\"brown-train.txt\", print_data=True)\n",
    "testset=load_dataset(\"brown-test.txt\", print_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c8a1d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM', 'PRON', 'PRT', 'VERB', 'X']\n"
     ]
    }
   ],
   "source": [
    "with open(\"brown-tag.txt\",\"r\") as f:\n",
    "    tags=[tag.strip() for tag in f.readlines()]\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "192af9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words (include punctuation): 44993\n",
      "number of words (include punctuation): 928327\n",
      "number of sentence: 45800\n",
      "number of unique words (include punctuation): 23114\n",
      "number of words (include punctuation): 232865\n",
      "number of sentence: 11540\n"
     ]
    }
   ],
   "source": [
    "def cnt_sen_and_word(dataset):\n",
    "    words=[word for item in dataset for word,lab in item]\n",
    "    print(\"number of unique words (include punctuation):\",len(set(words)))\n",
    "    print(\"number of words (include punctuation):\",len(words))\n",
    "    print(\"number of sentence:\", len(dataset))\n",
    "    \n",
    "cnt_sen_and_word(trainset)\n",
    "cnt_sen_and_word(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c93ff172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". : [117723, 29842]\n",
      "ADJ : [66985, 16736]\n",
      "ADP : [115752, 29014]\n",
      "ADV : [44765, 11474]\n",
      "CONJ : [30455, 7696]\n",
      "DET : [109418, 27601]\n",
      "NOUN : [220451, 55107]\n",
      "NUM : [11921, 2953]\n",
      "PRON : [39657, 9677]\n",
      "PRT : [23889, 5940]\n",
      "VERB : [146199, 36551]\n",
      "X : [1112, 274]\n"
     ]
    }
   ],
   "source": [
    "cnt_tr=dict.fromkeys(tags,0)\n",
    "cnt_te=dict.fromkeys(tags,0)\n",
    "for sent in trainset:\n",
    "    for item in sent:\n",
    "        cnt_tr[item[1]]+=1\n",
    "for sent in testset:\n",
    "    for item in sent:\n",
    "        cnt_te[item[1]]+=1\n",
    "for tag in tags:\n",
    "    print(tag,\":\",[cnt_tr[tag], cnt_te[tag]])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d633df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 --- Build a baseline method, namely, the most frequent tagger ---\n",
    "#     If you can recall, we introduced a strong baseline method (See Dan's book in \n",
    "# https://web.stanford.edu/~jurafsky/slp3/ed3book_jan72023.pdf Page 164.),\n",
    "#     where we label each word by using the most frequent-used tag associated with it.\n",
    "# 1). find the most frequent class label for each word in the training data.\n",
    "#     For example, {tr_word_1:tag_1,tr_word_2:tag_2,...}\n",
    "# 2). use your built method to predict tags for both train and test datasets.\n",
    "#     You should print out two values: the accuracies of train and test samples.\n",
    "#     You would expect that the accuracy on train will be > 0.9 (but never = 1.0) and higher than on test.\n",
    "\n",
    "# Notice: since there are unkown words in test samples. \n",
    "#  Following ways could handle this (choose one or create your own): \n",
    "#  1). mark all words that appear only once in the data with a \"UNK-x\" tag\n",
    "#  2). tag every out-of-vocabulary word with the majority tag among all training samples.\n",
    "#  3). find more methods in https://github.com/Adamouization/POS-Tagging-and-Unknown-Words\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7269710e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NOUN', 220451)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the majority tag among all training samples\n",
    "max(cnt_tr.items(),key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54dee88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the most frequent labels associated with each word\n",
    "def find_freq_labels(dataset):\n",
    "    word_labels = defaultdict(Counter)\n",
    "    for sent in dataset:\n",
    "        for item in sent:\n",
    "            word_labels[item[0]][item[1]] += 1\n",
    "    most_freq_labels = {}  \n",
    "    for word, counter in word_labels.items():\n",
    "        most_freq_labels[word] = counter.most_common(1)[0][0]\n",
    "    return most_freq_labels\n",
    "\n",
    "# compute accuracy (every out-of-vocabulary word with the majority tag among all training samples)\n",
    "def most_freq_acc(dataset, most_freq_labels):\n",
    "    correct=0\n",
    "    total=0\n",
    "    for sent in dataset:\n",
    "        for item in sent:\n",
    "            total+=1\n",
    "            if(most_freq_labels.get(item[0],'NOUN')==item[1]):\n",
    "                correct+=1\n",
    "    return correct/total*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "590acf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 95.56330904950518\n",
      "Accuracy on test set: 94.53932536018723\n"
     ]
    }
   ],
   "source": [
    "most_freq_labels=find_freq_labels(trainset)\n",
    "print(\"Accuracy on training set:\", most_freq_acc(trainset,most_freq_labels))\n",
    "print(\"Accuracy on test set:\", most_freq_acc(testset,most_freq_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "012f49a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark all words that appear only once in the data with \"UNK\"\n",
    "def process_train_dataset(dataset):\n",
    "    words=[]\n",
    "    for sent in dataset:\n",
    "        for word,tag in sent:\n",
    "            words.append(word)\n",
    "    vocab_freq=FreqDist(words)\n",
    "    vocab=set(vocab_freq.keys())-set(vocab_freq.hapaxes())\n",
    "    hapaxes=set(vocab_freq.hapaxes())\n",
    "    new_dataset=[]\n",
    "    for sent in dataset:\n",
    "        out=[(\"<UNK>\",tag) if word not in vocab else (word,tag) for word,tag in sent]\n",
    "        new_dataset.append(out)\n",
    "    return vocab, hapaxes, new_dataset\n",
    "\n",
    "def process_test_dataset(dataset, hapaxes, vocab):\n",
    "    new_dataset=[]\n",
    "    for sent in dataset:\n",
    "        out=[(\"<UNK>\",tag) if word not in vocab else (word,tag) for word,tag in sent]\n",
    "        new_dataset.append(out)\n",
    "    return new_dataset\n",
    "\n",
    "vocab, hapaxes, new_trainset=process_train_dataset(trainset)\n",
    "new_testset=process_test_dataset(testset, hapaxes, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "851e9220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 94.66416467473208\n",
      "Accuracy on test set: 94.0141283576321\n"
     ]
    }
   ],
   "source": [
    "new_most_freq_labels=find_freq_labels(new_trainset)\n",
    "print(\"Accuracy on training set:\", most_freq_acc(new_trainset, new_most_freq_labels))\n",
    "print(\"Accuracy on test set:\", most_freq_acc(new_testset, new_most_freq_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e38802c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 --- Build an HMM tagger ---\n",
    "# 1) You should use nltk.tag.HiddenMarkovModelTagger to build an HMM tagger.\n",
    "#    It has parameters: symbols, states, transitions, outputs, priors, transform (ignore it).\n",
    "#    Specify these parameters properly. For example, you can use MLE to estimate transitions, outputs and priors.\n",
    "#    That is, MLE to estimate matrix A (transition matrix), and matrix B (output probabilites) (See. Page 8.4.3)\n",
    "# 2) After build your model, report both the accuracy of HMM tagger for train samples and test samples.\n",
    "# \n",
    "# 3) Compared with your baseline method, discuss that why your HMM tagger is better/worse than baseline method.\n",
    "\n",
    "# Notice: You may also need to handle unknown words just like Task 2.\n",
    "\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e75f3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_hmm_para_MLE(dataset):\n",
    "    # symbols: seq of any\n",
    "    symbols = unique_list(word for sent in dataset for word, tag in sent)\n",
    "\n",
    "    # states: seq of any\n",
    "    states = unique_list(tag for sent in dataset for word, tag in sent)  \n",
    "\n",
    "    # transitions: ConditionalProbDistI\n",
    "    _transitions=[]\n",
    "    for sent in dataset:\n",
    "        for i in range(len(sent)-1):\n",
    "            _transitions.append((sent[i][1],sent[i+1][1]))\n",
    "    transitions=ConditionalProbDist(ConditionalFreqDist(_transitions), MLEProbDist)\n",
    "    \n",
    "    # outputs: ConditionalProbDistI\n",
    "    _outputs=[]\n",
    "    for sent in dataset:\n",
    "        for word,tag in sent:\n",
    "            _outputs.append((tag, word))\n",
    "    outputs=ConditionalProbDist(ConditionalFreqDist(_outputs), MLEProbDist)\n",
    "\n",
    "    # prior: ProbDistI\n",
    "    _priors=[]\n",
    "    for sent in dataset:\n",
    "        word,tag=sent[0]\n",
    "        _priors.append(tag)\n",
    "    priors=MLEProbDist(FreqDist(_priors))  \n",
    "\n",
    "    return symbols, states, transitions, outputs, priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17b2944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over 928327 tokens: 97.42\n",
      "accuracy over 232865 tokens: 81.41\n"
     ]
    }
   ],
   "source": [
    "symbols, states, transitions, outputs, priors=gen_hmm_para_MLE(trainset)\n",
    "tagger1=HiddenMarkovModelTagger(symbols, states, transitions, outputs, priors)\n",
    "tagger1.test(trainset)\n",
    "tagger1.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "440d4071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over 928327 tokens: 96.57\n",
      "accuracy over 232865 tokens: 95.86\n"
     ]
    }
   ],
   "source": [
    "symbols, states, transitions, outputs, priors=gen_hmm_para_MLE(new_trainset)\n",
    "tagger1=HiddenMarkovModelTagger(symbols, states, transitions, outputs, priors)\n",
    "tagger1.test(new_trainset)\n",
    "tagger1.test(new_testset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "448ec12d",
   "metadata": {},
   "source": [
    "| Tagger | Accuracy on trainset | Accuracy on testset |\n",
    "| --- | --- | --- |\n",
    "| Baseline+MostFreq | 95.56 | 94.53 |\n",
    "| Baseline+MostFreq+UNK | <font color=green>94.66</font> | 94.01 |\n",
    "| HMM+MLE | <font color=red>97.42</font> | <font color=green>81.41</font>|\n",
    "| HMM+MLE+UNK | 96.57 | <font color=red>95.86</font> |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6525bcaa",
   "metadata": {},
   "source": [
    "Baseline标注器使用UNK处理低频词后在训练集和测试集上表现均有所下降，这是因为使用unk处理后丢失了原先数据集中的信息。\n",
    "\n",
    "HMM标注器的MLE方法在我们的实验中产生过拟合问题，在训练集表现最好，在测试集表现最差，这是因为它会给未出现的事件分配零概率，这样就会导致一些标记永远不会被预测到。\n",
    "\n",
    "UNK处理后HMM缓解了过拟合，能够改善模型对未知词汇和低频词的识别能力，并通过观察其上下文信息来预测其标注，从而提高模型总体性能，在测试集表现最好。\n",
    "\n",
    "下面对MLE方法进行平滑，看是否会改善HMM的表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a97cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_hmm_para_Lidstone(dataset):\n",
    "    estimator = lambda fdist, bins: LidstoneProbDist(fdist, 0.1, bins)\n",
    "    # estimator = lambda fdist, bins: MLEProbDist(fdist)\n",
    "    \n",
    "    # symbols: seq of any\n",
    "    symbols = unique_list(word for sent in dataset for word, tag in sent)\n",
    "\n",
    "    # states: seq of any\n",
    "    states = unique_list(tag for sent in dataset for word, tag in sent)  \n",
    "\n",
    "    # transitions: ConditionalProbDistI\n",
    "    _transitions=[]\n",
    "    for sent in dataset:\n",
    "        for i in range(len(sent)-1):\n",
    "            _transitions.append((sent[i][1],sent[i+1][1]))\n",
    "    transitions=ConditionalProbDist(ConditionalFreqDist(_transitions), estimator, len(states))\n",
    "    \n",
    "    # outputs: ConditionalProbDistI\n",
    "    _outputs=[]\n",
    "    for sent in dataset:\n",
    "        for word,tag in sent:\n",
    "            _outputs.append((tag, word))\n",
    "    outputs=ConditionalProbDist(ConditionalFreqDist(_outputs), estimator, len(symbols))\n",
    "\n",
    "    # prior: ProbDistI\n",
    "    _priors=[]\n",
    "    for sent in dataset:\n",
    "        word,tag=sent[0]\n",
    "        _priors.append(tag)\n",
    "    priors=estimator(FreqDist(_priors), len(states))  \n",
    "\n",
    "    return symbols, states, transitions, outputs, priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fadaa4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over 928327 tokens: 96.95\n",
      "accuracy over 232865 tokens: 95.33\n"
     ]
    }
   ],
   "source": [
    "symbols, states, transitions, outputs, priors=gen_hmm_para_Lidstone(trainset)\n",
    "tagger1=HiddenMarkovModelTagger(symbols, states, transitions, outputs, priors)\n",
    "tagger1.test(trainset)\n",
    "tagger1.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfdb3243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over 928327 tokens: 96.35\n",
      "accuracy over 232865 tokens: 95.72\n"
     ]
    }
   ],
   "source": [
    "symbols, states, transitions, outputs, priors=gen_hmm_para_Lidstone(new_trainset)\n",
    "tagger1=HiddenMarkovModelTagger(symbols, states, transitions, outputs, priors)\n",
    "tagger1.test(new_trainset)\n",
    "tagger1.test(new_testset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "821ff718",
   "metadata": {},
   "source": [
    "| Tagger | Accuracy on trainset | Accuracy on testset |\n",
    "| --- | --- | --- |\n",
    "| Baseline+MostFreq | 95.56 | 94.53 |\n",
    "| Baseline+MostFreq+UNK | <font color=green>94.66</font> | 94.01 |\n",
    "| HMM+MLE | <font color=red>97.42</font> | <font color=green>81.41</font>|\n",
    "| HMM+MLE+UNK | 96.57 | <font color=red>95.86</font> |\n",
    "| HMM+Lidstone | 96.95 | 95.33|\n",
    "| HMM+Lidstone+UNK | 96.35 | 95.72 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4d2012a",
   "metadata": {},
   "source": [
    "可以看到Lidstone smoothing方法提升了不使用UNK处理的测试集上的表现，这是因为通过将每个计数增加一个平滑常量来避免了过拟合。而同时使用Lidstone Smoothing和UNK可能会导致过度平滑，从而降低标注器的预测准确性。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
